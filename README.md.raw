# PyNum4Dummies

## Aims
This project consists in a library `solver_tools` and a bunch of python scripts.

The library aims at solving "easy" 1d partial differential equations (pdes), for education and research.


### Exemples of pdes:
* The heat equation $ \frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2} $
* Burger equation $ \frac{\partial u} {\partial t} = -u \frac{\partial u}{\partial x} $
* The advection equation $ \frac{\partial u} {\partial t} = -c \frac{\partial u}{\partial x} $


## Files
The project consists in a library and a collection of scripts that illustrates it.


### The librairie 
`solver_tools.py`

It contains:
* a function to integrate the equation $ \frac{\partial u}{\partial t} = RHS(u,x,t) $
* discretization of:
  * space derivative: $f(a,u,x,t) = a \frac{\partial u}{\partial x}$
    - LUD
    - upwind
  * second space derivative $f(u,x,t) = \frac{\partial^2 u}{\partial x^2}$
    - central_scheme
* cfl (compute and print the cfl number)
* functions to compute the adjoint of the pdes in order to compute gradient of possibly complex costs functions
  - data assimilation (identify initial conditions that allows to fit the model on the data available)
  - model assimilation (identify model parameters that allows to fit the model on the data available)

Other functions will be implemented, to derive reduced order models (ROM) of the equation, as well as computing the adjoint variables (see later).

### The scripts
The various scripts illustrate the use of the library:
* `script_assimilation.py` - data assimilation (model and/or CI)
* `script_advection.py` - advection equation
* `script_test_accuracy.py` - test the accuracy of the solver
* `script_unsteady_bc.py` - illlustrates unsteady boundary conditions
* `script_burgers_inviscid.py` - inviscid burger equation
* `script_viscous_burgers.py` - viscous burger equation
* `script_operators.py` - general equation


# Todo:
- [x] add adjoint
- [ ] advection: instabilities in LUD when too stiff ? Flux limiter ?
- [ ] add $\partial_{xxx}$/ $\partial_{xxxx}$ for KdW or Kuramotoâ€“Sivashinsky equations ?
# Explanations
## Provided discretization schemes
### Advection
LUD is the Linear Upwind Differencing scheme. It has significantly less dissipation than the regular upwind scheme.
It is used to discretize, in space, the following advection-type operator:

$$ a \frac{\partial u} {\partial x} $$ 

$a$ does not have to be a constant: it can actually be $a(u,t)$.

### Diffusion
central difference scheme is used to discretize, in space, the following diffusion-type operator:

$$ nu \frac{\partial^2 u} {\partial x^2} $$ 

### Solving a Partial Differential Equation
Let's use a simple example here, the Burger equation:
$$ \mathcal{F}(u,t) := \frac{\partial u} {\partial t}  + u \frac{\partial u}{\partial x}  - \nu \frac{\partial^2 u}{\partial x^2} = 0$$

> $\mathcal{F}$ can be constructed as a list of operators: $ \mathcal{F} = \sum_i L_i u$.

In the present approach, we chose to separate the time derivative operator from the spatial operators:
$$ \frac{\partial u} {\partial t}  = - u \frac{\partial u}{\partial x}  + \nu \frac{\partial^2 u}{\partial x^2} = L_1 u  + L_2 u$$

with $L_1 u = - u \frac{\partial u}{\partial x} $ and $L_2 u =  \nu \frac{\partial^2 u}{\partial x^2}$. Clearly, these operators can be nonlinear.

> The list of RHS operators $[L_1,L_2]$ will be passed to `integration_forward`, in order to solve the pde.


### Computing the gradient of the cost functional

We want to look at the problem depending on some parameters:

$$
J(u,q) = \int_0^1 
		j(u,q,t)	
	{\textrm d}t 
$$
s.t. the physics:
$$
\mathcal{F}(u,\dot{u},q,t) = 0
$$

> The physics is solved using the function `integration_forward`

For instance, considering $q\equiv \{q_c,q_u\}$, and the inviscid Burgers' equation, we have

$$
\mathcal{F}(u,\dot{u},q,t) := \frac{\partial u} {\partial t} + q_c u \frac{\partial u}{\partial x}  = 0
$$


If the cost function means fitting the model on available data $y(t)$, then, one have:

$$
j(u,q,t) := |u(t) - y(t)|.
$$


We are also considering that the initial conditions are (potentially) related to the parameters q with:
$$
g(u(0),q) = 0
$$

> $j$ and $g$ do not have to be constructed. In practice, only their partial derivatives w.r.t. $u$ and $q$ will be needed.

For instance, if the initial conditions are actually the parameter $q_u$:

$$ 
	g(u(0),q) := u(0) - q_u =0.
$$

We want to find the argmin of J.
This formalism is usefull in numerous situations, e.g.:
* to identify the parameters of a model that will match some data
* some initial conditions that will reproduce as good as possible the provided data.
* optimal control, so that $u$ will reach a given state or follow a given trajectory.
* more generally any user-defined constrains expressed in the form of $J$.

Identifying the minimum of the $J$ relies on the gradient of the functional with respect to the parameters:
$D_q J = \frac{D\,J}{Dq}$. 

Estimation of the gradient with finite differentiation is out of reach if the size of $q$ is large (if $n_q$ is the size of $q$, then $2 n_q$ evaluation of the system are needed).

For that, one can introduce the Lagrangian $ \mathcal{L} := \mathcal{L} \bigg(u,\dot{u},q,\lambda,\mu\bigg)$, associated with the two Lagrange parameters $\lambda$ and $\mu$ (variables are dropped for visibility):

$$
   \mathcal{L} = 
    \int_0^1 \bigg[ j  +  {\lambda}^T \mathcal{F}  \bigg] {\textrm d}t + {\mu}^T g,
$$

where $^T$ is the transpose operator. 
Naturally, both $u$ and $\dot{u}$ are considered as variables.


The gradient $D_q \mathcal{L} = \frac{D L}{Dq}$ of $ \mathcal{L}$ is
$$
		D_q \mathcal{L} = 
			\int_0^1  \bigg[
				\partial_u j \partial_q u  +\partial_q j 
				+ \lambda^T \partial_u \mathcal{F} \partial_q u 
			    + \lambda^T\partial_{ \dot{u} } \mathcal{F} \partial_q \dot{u}  
			    + \lambda^T\partial_q \mathcal{F} 
				\bigg] {\textrm d}t 
		   +    {\mu}^T \partial_{u(0)} g \partial_q u(0)  
		   +    {\mu}^T \partial_q g.
$$

Upon optimality, one has $D_q \mathcal{L} = D_q J$.

The term in $\partial_{\dot{u}}$ cannot be easily estimated. An integration by parts gives:


$$
		\int_0^1   {   {\lambda}}^T\partial_{\dot{u}} \mathcal{F}  \partial_q \dot{u} {\textrm d}t = 
		  \left[   {\lambda}^T\partial_{\dot{u}} \mathcal{F}  \partial_q u \right]_0^T 
		   - \int_0^T \left\{\dot{   {\lambda}}^T\partial_{\dot{u}} \mathcal{F}  \right. 
		   \left. +    {\lambda}^T \partial_t \partial_{\dot{u}} \mathcal{F}  \right\} \partial_q u {\textrm d}t.
$$


The term associated with $\partial_{ \dot{u} }$ can now be replaced.

Ordering terms leads to:

$$
	D_q \mathcal{L}  = 
		\int_0^1  
			\bigg[
					\bigg(
						\partial_u j  + \lambda^T \partial_u  \mathcal{F}
						-\bigg\{ 
							\dot{ \lambda}^T \partial_{ \dot{u} } \mathcal{F} 
				   			+ \lambda^T \partial_t \partial_{ \dot{u} } \mathcal{F}   
						\bigg\}
					\bigg) {\textrm d}_q u
		 	+ \partial_q j + \lambda^T\partial_q \mathcal{F}  
			\bigg] {\textrm d}t  
	  	+ \left.
			\bigg(
			   \mu^T \partial_u g  
	 		 	- \lambda^T \partial_{ \dot{u} } \mathcal{F}   
			\bigg)
		\right|_0 \partial_q u(0)
 		+ \mu^T \partial_q g 
	   	+ \left.
			\bigg(  
				\lambda^T \partial_{ \dot{u} } \mathcal{F}  
			\bigg) 
		\right|_T \partial_q u(T)
$$

As $\mathcal{F}$ and $g$ are null by construction, $\lambda$ and $\mu$ can be designed specifically to alleviate the computations.

Indeed, proper choices for $ \lambda $ and $\mu$ allow to simplify the expression of $D_q \mathcal{L}$.

The choice of $ \lambda (T) =  0$ nullifies the term $\left.\bigg( \lambda^T \partial_{ \dot{u} } \mathcal{F}  \bigg) \right|_T \partial_q u(T)$.
$ \lambda $ can then be chosen as the solution of the so-called adjoint equation(see Ledimet 1986,Talagrand 1997):

$$
		\bigg( 
			\partial_u j    +    \lambda^T \partial_u  \mathcal{F}  
			- \bigg\{ 
					\dot{\lambda}^T \partial_{ \dot{u} } \mathcal{F}  
				   + \lambda^T \partial_t \partial_{ \dot{u} } \mathcal{F}   
			\bigg\}
		\bigg) 
			=  0,
$$
integrated backwards in time. 

> This equation is solved using the function `integration_backward`

To do so, linearize $\mathcal{F}$ around $u$ and replace $u$ 


Finally, the Lagrange parameter $ \mu $ is set so that it nullifies the component associated with $\partial_q u(0)$:

$$ \left.  \bigg\{ \mu^T \partial_u g   -  \lambda^T\partial_{\dot{u}} \mathcal{F}   \bigg\} \right|_0 = 0.$$

Then, computing $D_q \mathcal{L}$, hence $ D_qJ$, is achieved by the integration of:

$$
		 D_qJ \bigg(u,q\bigg) = 
		  \int_0^1  \bigg[  \partial_q j     +  \lambda ^T\partial_q \mathcal{F}  \bigg] {\textrm d}t 
		  +      \mu^T \partial_q g.
$$

> This equation is solved using the function `gradient_q`

